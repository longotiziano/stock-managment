services:
  zookeeper: 
    image: confluentinc/cp-zookeeper:7.5.0 
    environment:
      ZOOKEEPER_CLIENT_PORT: 2181 
    ports:
      - "2181:2181" 

  kafka:
    image: confluentinc/cp-kafka:7.5.0
    depends_on:
      - zookeeper 
    ports:
      - "9092:9092" 
    environment:
      KAFKA_BROKER_ID: 1
      KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181
      KAFKA_LISTENERS: PLAINTEXT://0.0.0.0:9092 
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://kafka:9092 
      KAFKA_AUTO_CREATE_TOPICS_ENABLE: "true"
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
      KAFKA_TRANSACTION_STATE_LOG_REPLICATION_FACTOR: 1
      KAFKA_TRANSACTION_STATE_LOG_MIN_ISR: 1

  db:
    image: postgres
    restart: always
    environment:
      POSTGRES_USER: ${POSTGRES_USER}
      POSTGRES_PASSWORD: ${POSTGRES_PASSWORD}
      POSTGRES_DB: ${POSTGRES_DB}
    env_file:
      - .env
    ports:
      - "5432:5432"
    volumes:
      - pgdata:/var/lib/postgresql/data 
      - ./sql/init.sql:/docker-entrypoint-initdb.d/init.sql
      - ./sql/backups:/docker-entrypoint-initdb.d/backups
      - ./sql/airflow_db_init.sh:/docker-entrypoint-initdb.d/airflow_db_init.sh
  pgadmin:
    image: dpage/pgadmin4
    restart: always
    environment:
      PGADMIN_DEFAULT_EMAIL: ${PGADMIN_DEFAULT_EMAIL}
      PGADMIN_DEFAULT_PASSWORD: ${PGADMIN_DEFAULT_PASSWORD}
    env_file:
      - .env
    ports:
      - "8081:80"
    depends_on:
      - db

  python:
    build:
      context: .
      dockerfile: Dockerfile
    env_file:
      - .env
    depends_on:
      - kafka
      - db
    volumes:
      - ./:/app 

  airflow-webserver:
    build:
      context: ./
      dockerfile: airflow_folder/Dockerfile
    restart: always
    ports:
      - "8080:8080"
    command: webserver
    environment:
      AIRFLOW__CORE__EXECUTOR: LocalExecutor
      AIRFLOW__DATABASE__SQL_ALCHEMY_CONN: postgresql+psycopg2://${POSTGRES_USER}:${POSTGRES_PASSWORD}@db/${POSTGRES_DB_AIRFLOW}
      AIRFLOW__WEBSERVER__SECRET_KEY: ${AIRFLOW_SECRET_KEY}
    env_file:
      - .env
    volumes:
      - ./airflow_folder/dags:/opt/airflow/dags
      - ./app:/opt/airflow/app
      - ./sql:/opt/airflow/sql
      - ./data:/opt/airflow/data

  airflow-scheduler:
    build:
      context: ./
      dockerfile: airflow_folder/Dockerfile
    restart: always
    command: scheduler
    environment:
      AIRFLOW__SCHEDULER__SCHEDULER_HEARTBEAT_SEC: 5
      AIRFLOW__SCHEDULER__MIN_FILE_PROCESS_INTERVAL: 30
      AIRFLOW__SCHEDULER__DAG_DIR_LIST_INTERVAL: 30
      AIRFLOW__CORE__EXECUTOR: LocalExecutor
      AIRFLOW__DATABASE__SQL_ALCHEMY_CONN: postgresql+psycopg2://${POSTGRES_USER}:${POSTGRES_PASSWORD}@db/${POSTGRES_DB_AIRFLOW}
      AIRFLOW__WEBSERVER__SECRET_KEY: ${AIRFLOW_SECRET_KEY}
    env_file:
      - .env
    volumes:
      - ./airflow_folder/dags:/opt/airflow/dags
      - ./app:/opt/airflow/app
      - ./sql:/opt/airflow/sql
      - ./data:/opt/airflow/data  

  airflow-init:
    image: apache/airflow:2.9.1
    depends_on:
      - db
    entrypoint: /opt/airflow/airflow_init.sh
    environment:
      AIRFLOW__CORE__EXECUTOR: LocalExecutor
      AIRFLOW__DATABASE__SQL_ALCHEMY_CONN: postgresql+psycopg2://${POSTGRES_USER}:${POSTGRES_PASSWORD}@db/${POSTGRES_DB_AIRFLOW}
      AIRFLOW__WEBSERVER__SECRET_KEY: ${AIRFLOW_SECRET_KEY}
    env_file:
      - .env
    volumes:
      - ./airflow_folder/dags:/opt/airflow/dags
      - ./app:/opt/airflow/app
      - ./sql:/opt/airflow/sql
      - ./data:/opt/airflow/data
      - ./airflow_folder/airflow_init.sh:/opt/airflow/airflow_init.sh
  
volumes:
  pgdata:

